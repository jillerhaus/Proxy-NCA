{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import imp\n",
    "import dataset\n",
    "import utils\n",
    "import proxynca\n",
    "import net\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "from utils import JSONEncoder, json_dumps\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Args Class\n",
    "\n",
    "Class containing the parameters for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args():\n",
    "    dataset = 'food_test'\n",
    "    config = 'config1.json'\n",
    "    sz_embedding = 64 #size of the embedding that is appendet to inceptionv2\n",
    "    sz_batch = 32 #number of samples per batch\n",
    "    nb_epochs = 20\n",
    "    gpu_id = 0\n",
    "    nb_workers = 4\n",
    "    with_nmi = True  #turn calculations for nmi on or off turn off for sop\n",
    "    scaling_x = 3.0 #scaling factor for the normalized embeddings\n",
    "    scaling_p = 3.0 #scaling factor for the normalized proxies\n",
    "    lr_proxynca = 1.0 #learning rate for proxynca\n",
    "    log_filename = (f'''{dataset}-{dt.now().strftime(\"%Y%m%d-%H%M%S\")}''')\n",
    "    results_filename = f'{dataset}-results.csv'\n",
    "    torch_version = str(torch.__version__)\n",
    "    edition = 0\n",
    "    seed = 0\n",
    "    train_classes = None\n",
    "    eval_classes = None\n",
    "    p_c = 1 #Number of proxies per class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(args = args):\n",
    "    seed = args.seed\n",
    "    if seed != -1:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    else:\n",
    "        print('not seeded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(args.gpu_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_config(args = args):\n",
    "    config = utils.load_config(args.config)\n",
    "    config['criterion']['args']['scaling_x'] = args.scaling_x\n",
    "    config['criterion']['args']['scaling_p'] = args.scaling_p\n",
    "    config['opt']['args']['proxynca']['lr'] = args.lr_proxynca\n",
    "    if args.train_classes:\n",
    "        config['dataset'][args.dataset]['classes']['train'] = args.train_classes\n",
    "    if args.eval_classes:\n",
    "        config['dataset'][args.dataset]['classes']['eval'] = args.eval_classes\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_tr(config = setup_config(), args = args):\n",
    "    dl_tr = torch.utils.data.DataLoader(\n",
    "        dataset.load(name = args.dataset,\n",
    "                     root = config['dataset'][args.dataset]['root'],\n",
    "                     classes = config['dataset'][args.dataset]['classes']['train'],\n",
    "                     transform = dataset.utils.make_transform(**config['transform_parameters'])\n",
    "                    ),\n",
    "        batch_size = args.sz_batch,\n",
    "        shuffle = True,\n",
    "        num_workers = args.nb_workers,\n",
    "        drop_last = True,\n",
    "        pin_memory = True\n",
    "    )\n",
    "    return dl_tr\n",
    "\n",
    "def load_ev(config = setup_config(), args = args):\n",
    "    dl_ev = torch.utils.data.DataLoader(\n",
    "        dataset.load(\n",
    "            name = args.dataset,\n",
    "            root = config['dataset'][args.dataset]['root'],\n",
    "            classes = config['dataset'][args.dataset]['classes']['eval'],\n",
    "            transform = dataset.utils.make_transform(\n",
    "                **config['transform_parameters'],\n",
    "                is_train = False)\n",
    "        ),\n",
    "        batch_size = args.sz_batch,\n",
    "        shuffle = False,\n",
    "        num_workers = args.nb_workers,\n",
    "        pin_memory = True\n",
    "    )\n",
    "    return dl_ev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model(args = args):\n",
    "    model = net.bn_inception(pretrained = True)\n",
    "    net.embed(model, sz_embedding = args.sz_embedding)\n",
    "    model = model.cuda()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterion\n",
    "\n",
    "This function initializes the training class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_criterion(config = setup_config(), args = args, dl_tr = load_tr()):\n",
    "    criterion = proxynca.ProxyNCA(\n",
    "        nb_classes = dl_tr.dataset.nb_classes(),\n",
    "        sz_embedding = args.sz_embedding,\n",
    "        p_c = args.p_c,\n",
    "        **config['criterion']['args']).cuda()\n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_opt(config = setup_config(), model = setup_model(), criterion = setup_criterion()):\n",
    "    opt = config['opt']['type'](\n",
    "        [\n",
    "            { # inception parameters, excluding embedding layer\n",
    "                **{'params': list(\n",
    "                    set(\n",
    "                        model.parameters()\n",
    "                    ).difference(\n",
    "                        set(model.embedding_layer.parameters())\n",
    "                    )\n",
    "                )},\n",
    "                **config['opt']['args']['backbone']\n",
    "            },\n",
    "            { # embedding parameters\n",
    "                **{'params': model.embedding_layer.parameters()},\n",
    "                **config['opt']['args']['embedding']\n",
    "            },\n",
    "            { # proxy nca parameters\n",
    "                **{'params': criterion.parameters()},\n",
    "                **config['opt']['args']['proxynca']\n",
    "            }\n",
    "        ],\n",
    "        **config['opt']['args']['base']\n",
    "    )\n",
    "    return opt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_scheduler(config = setup_config(), opt = setup_opt()):\n",
    "    scheduler = config['lr_scheduler']['type'](\n",
    "        opt, **config['lr_scheduler']['args'])\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging(args = args):\n",
    "    imp.reload(logging)\n",
    "    logging.basicConfig(\n",
    "        format = \"%(asctime)s %(message)s\",\n",
    "        level = logging.INFO,\n",
    "        handlers = [\n",
    "            logging.FileHandler(\"{0}/{1}.log\".format('log', args.log_filename)),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    logging.info(\"Training parameters: {}\".format(vars(args)))\n",
    "    logging.info(\"Training for {} epochs\".format(args.nb_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(args = args):\n",
    "    #set up new parameters\n",
    "    seed_everything(args)\n",
    "    config = setup_config(args)\n",
    "    dl_tr = load_tr(config, args)\n",
    "    dl_ev = load_ev(config, args)\n",
    "    model = setup_model(args = args)\n",
    "    criterion = setup_criterion(config = config, args = args, dl_tr = load_tr())\n",
    "    opt = setup_opt(config = config, model = model, criterion = criterion)\n",
    "    scheduler = setup_scheduler(config = config, opt = opt)\n",
    "    setup_logging(args = args)\n",
    "    \n",
    "    if args.with_nmi == True:\n",
    "        df = pd.DataFrame(columns = ['epoch', 'r@1', 'r@2', 'r@4', 'r@8', 'NMI'])\n",
    "    else:\n",
    "        df = pd.DataFrame(columns = ['epoch', 'r@1', 'r@2', 'r@4','r@8'])\n",
    "    \n",
    "    losses = []\n",
    "    t1 = time.time()\n",
    "    logging.info(\"**Evaluating initial model.**\")\n",
    "    with torch.no_grad():\n",
    "        utils.evaluate(model, dl_ev, with_nmi = args.with_nmi)\n",
    "\n",
    "    for e in range(0, args.nb_epochs):\n",
    "        if e!=0:\n",
    "            scheduler.step()\n",
    "        time_per_epoch_1 = time.time()\n",
    "        losses_per_epoch = []\n",
    "        for x,y, _ in dl_tr:\n",
    "            opt.zero_grad()\n",
    "            m = model(x.cuda())\n",
    "            loss = criterion(m, y.cuda())\n",
    "            loss.backward()\n",
    "\n",
    "#             torch.nn.utils.clip_grad_value_(model.parameters(), 10)\n",
    "            \n",
    "            losses_per_epoch.append(loss.data.cpu().numpy())\n",
    "            opt.step()\n",
    "\n",
    "        time_per_epoch_2 = time.time()\n",
    "        losses.append(np.mean(losses_per_epoch[-20:]))\n",
    "        logging.info(\n",
    "            \"Epoch: {}, loss: {:.3f}, time (seconds): {:.2f}.\".format(\n",
    "                e,\n",
    "                losses[-1],\n",
    "                time_per_epoch_2 - time_per_epoch_1))\n",
    "        with torch.no_grad():\n",
    "            logging.info(\"**Evaluating.**\")\n",
    "            recall = utils.evaluate(model, dl_ev, with_nmi = args.with_nmi) #variable name not accurate\n",
    "            # append results of current epoch to df\n",
    "            if args.with_nmi == True:\n",
    "                lst = recall[0].copy()\n",
    "                lst.append(recall[1])\n",
    "                lst.insert(0,e)\n",
    "                df_epoch = pd.DataFrame([lst], columns = ['epoch', 'r@1', 'r@2', 'r@4','r@8', 'NMI'])\n",
    "            else:\n",
    "                lst = recall.copy()\n",
    "                lst.insert(0,e)\n",
    "                df_epoch = pd.DataFrame([lst], columns = ['epoch', 'r@1', 'r@2', 'r@4', 'r@8'])\n",
    "            df = pd.concat([df,df_epoch])\n",
    "            model.losses = losses\n",
    "            model.current_epoch = e\n",
    "\n",
    "    t2 = time.time()\n",
    "    logging.info(\"Total training time (minutes): {:.2f}.\".format((t2 - t1) / 60))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped version:0. It was already done.\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-29 20:56:53,073 Training parameters: {'__module__': '__main__', 'dataset': 'food_test', 'config': 'config1.json', 'sz_embedding': 64, 'sz_batch': 128, 'nb_epochs': 20, 'gpu_id': 0, 'nb_workers': 4, 'with_nmi': True, 'scaling_x': 1.0, 'scaling_p': 1.0, 'lr_proxynca': 1, 'log_filename': 'food_test-20200929-205650', 'results_filename': 'food_test-results.csv', 'torch_version': '1.1.0', 'edition': 0, 'seed': 1, 'train_classes': range(0, 50), 'eval_classes': range(50, 101), 'p_c': 1, '__dict__': <attribute '__dict__' of 'args' objects>, '__weakref__': <attribute '__weakref__' of 'args' objects>, '__doc__': None}\n",
      "2020-09-29 20:56:53,074 Training for 20 epochs\n",
      "2020-09-29 20:56:53,076 **Evaluating initial model.**\n",
      "2020-09-29 20:57:50,179 NMI: 26.584\n",
      "2020-09-29 20:58:02,547 R@1 : 32.728\n",
      "2020-09-29 20:58:02,803 R@2 : 42.287\n",
      "2020-09-29 20:58:03,051 R@4 : 53.220\n",
      "2020-09-29 20:58:03,302 R@8 : 64.404\n",
      "2020-09-29 20:58:38,134 Epoch: 0, loss: 3.320, time (seconds): 34.83.\n",
      "2020-09-29 20:58:38,135 **Evaluating.**\n",
      "2020-09-29 20:59:14,075 NMI: 30.861\n",
      "2020-09-29 20:59:25,845 R@1 : 38.038\n",
      "2020-09-29 20:59:26,107 R@2 : 47.736\n",
      "2020-09-29 20:59:26,357 R@4 : 57.956\n",
      "2020-09-29 20:59:26,601 R@8 : 67.794\n",
      "2020-09-29 21:00:00,387 Epoch: 1, loss: 3.142, time (seconds): 33.78.\n",
      "2020-09-29 21:00:00,387 **Evaluating.**\n",
      "2020-09-29 21:00:35,526 NMI: 30.799\n",
      "2020-09-29 21:00:47,047 R@1 : 38.107\n",
      "2020-09-29 21:00:47,295 R@2 : 48.119\n",
      "2020-09-29 21:00:47,543 R@4 : 58.295\n",
      "2020-09-29 21:00:47,789 R@8 : 68.028\n",
      "2020-09-29 21:01:21,316 Epoch: 2, loss: 3.039, time (seconds): 33.53.\n",
      "2020-09-29 21:01:21,317 **Evaluating.**\n",
      "2020-09-29 21:01:56,422 NMI: 30.988\n",
      "2020-09-29 21:02:07,775 R@1 : 37.960\n",
      "2020-09-29 21:02:08,020 R@2 : 48.136\n",
      "2020-09-29 21:02:08,265 R@4 : 57.834\n",
      "2020-09-29 21:02:08,509 R@8 : 67.298\n",
      "2020-09-29 21:02:42,355 Epoch: 3, loss: 2.993, time (seconds): 33.84.\n",
      "2020-09-29 21:02:42,356 **Evaluating.**\n",
      "2020-09-29 21:03:17,643 NMI: 30.512\n",
      "2020-09-29 21:03:29,256 R@1 : 37.177\n",
      "2020-09-29 21:03:29,511 R@2 : 47.258\n",
      "2020-09-29 21:03:29,763 R@4 : 57.591\n",
      "2020-09-29 21:03:30,031 R@8 : 66.855\n",
      "2020-09-29 21:04:04,190 Epoch: 4, loss: 2.967, time (seconds): 34.16.\n",
      "2020-09-29 21:04:04,191 **Evaluating.**\n",
      "2020-09-29 21:04:39,863 NMI: 30.104\n",
      "2020-09-29 21:04:51,141 R@1 : 36.421\n",
      "2020-09-29 21:04:51,389 R@2 : 46.215\n",
      "2020-09-29 21:04:51,637 R@4 : 56.809\n",
      "2020-09-29 21:04:51,884 R@8 : 66.820\n",
      "2020-09-29 21:05:25,419 Epoch: 5, loss: 2.937, time (seconds): 33.53.\n",
      "2020-09-29 21:05:25,420 **Evaluating.**\n",
      "2020-09-29 21:06:00,963 NMI: 29.900\n",
      "2020-09-29 21:06:12,227 R@1 : 35.352\n",
      "2020-09-29 21:06:12,471 R@2 : 45.790\n",
      "2020-09-29 21:06:12,723 R@4 : 56.357\n",
      "2020-09-29 21:06:12,972 R@8 : 66.464\n",
      "2020-09-29 21:06:46,384 Epoch: 6, loss: 2.892, time (seconds): 33.41.\n",
      "2020-09-29 21:06:46,385 **Evaluating.**\n",
      "2020-09-29 21:07:20,912 NMI: 30.184\n",
      "2020-09-29 21:07:32,123 R@1 : 35.352\n",
      "2020-09-29 21:07:32,366 R@2 : 45.798\n",
      "2020-09-29 21:07:32,612 R@4 : 56.496\n",
      "2020-09-29 21:07:32,860 R@8 : 66.525\n",
      "2020-09-29 21:08:06,324 Epoch: 7, loss: 2.887, time (seconds): 33.46.\n",
      "2020-09-29 21:08:06,325 **Evaluating.**\n",
      "2020-09-29 21:08:40,871 NMI: 28.976\n",
      "2020-09-29 21:08:52,159 R@1 : 33.910\n",
      "2020-09-29 21:08:52,429 R@2 : 44.347\n",
      "2020-09-29 21:08:52,704 R@4 : 55.271\n",
      "2020-09-29 21:08:52,956 R@8 : 65.604\n",
      "2020-09-29 21:09:26,613 Epoch: 8, loss: 2.858, time (seconds): 33.66.\n",
      "2020-09-29 21:09:26,614 **Evaluating.**\n",
      "2020-09-29 21:10:01,711 NMI: 29.105\n",
      "2020-09-29 21:10:12,981 R@1 : 34.257\n",
      "2020-09-29 21:10:13,228 R@2 : 44.295\n",
      "2020-09-29 21:10:13,473 R@4 : 54.628\n",
      "2020-09-29 21:10:13,719 R@8 : 65.143\n",
      "2020-09-29 21:10:47,718 Epoch: 9, loss: 2.854, time (seconds): 34.00.\n",
      "2020-09-29 21:10:47,719 **Evaluating.**\n",
      "2020-09-29 21:11:22,006 NMI: 29.312\n",
      "2020-09-29 21:11:33,259 R@1 : 34.005\n",
      "2020-09-29 21:11:33,503 R@2 : 43.930\n",
      "2020-09-29 21:11:33,746 R@4 : 54.749\n",
      "2020-09-29 21:11:33,993 R@8 : 65.291\n",
      "2020-09-29 21:12:07,765 Epoch: 10, loss: 2.846, time (seconds): 33.77.\n",
      "2020-09-29 21:12:07,766 **Evaluating.**\n",
      "2020-09-29 21:12:41,972 NMI: 28.915\n",
      "2020-09-29 21:12:53,161 R@1 : 33.119\n",
      "2020-09-29 21:12:53,407 R@2 : 43.139\n",
      "2020-09-29 21:12:53,652 R@4 : 53.628\n",
      "2020-09-29 21:12:53,898 R@8 : 64.178\n",
      "2020-09-29 21:13:27,722 Epoch: 11, loss: 2.829, time (seconds): 33.82.\n",
      "2020-09-29 21:13:27,722 **Evaluating.**\n",
      "2020-09-29 21:14:02,528 NMI: 28.909\n",
      "2020-09-29 21:14:13,701 R@1 : 32.545\n",
      "2020-09-29 21:14:13,946 R@2 : 43.035\n",
      "2020-09-29 21:14:14,189 R@4 : 54.019\n",
      "2020-09-29 21:14:14,445 R@8 : 64.291\n",
      "2020-09-29 21:14:48,163 Epoch: 12, loss: 2.809, time (seconds): 33.71.\n",
      "2020-09-29 21:14:48,164 **Evaluating.**\n",
      "2020-09-29 21:15:22,807 NMI: 28.232\n",
      "2020-09-29 21:15:34,023 R@1 : 32.789\n",
      "2020-09-29 21:15:34,268 R@2 : 43.069\n",
      "2020-09-29 21:15:34,514 R@4 : 53.906\n",
      "2020-09-29 21:15:34,760 R@8 : 64.083\n",
      "2020-09-29 21:16:08,470 Epoch: 13, loss: 2.796, time (seconds): 33.71.\n",
      "2020-09-29 21:16:08,470 **Evaluating.**\n",
      "2020-09-29 21:16:42,728 NMI: 27.804\n",
      "2020-09-29 21:16:53,926 R@1 : 32.033\n",
      "2020-09-29 21:16:54,173 R@2 : 42.192\n",
      "2020-09-29 21:16:54,418 R@4 : 53.046\n",
      "2020-09-29 21:16:54,665 R@8 : 64.213\n",
      "2020-09-29 21:17:28,482 Epoch: 14, loss: 2.783, time (seconds): 33.82.\n",
      "2020-09-29 21:17:28,483 **Evaluating.**\n",
      "2020-09-29 21:18:02,846 NMI: 27.465\n",
      "2020-09-29 21:18:14,098 R@1 : 30.981\n",
      "2020-09-29 21:18:14,371 R@2 : 41.410\n",
      "2020-09-29 21:18:14,644 R@4 : 52.611\n",
      "2020-09-29 21:18:14,914 R@8 : 63.083\n",
      "2020-09-29 21:18:48,820 Epoch: 15, loss: 2.780, time (seconds): 33.90.\n",
      "2020-09-29 21:18:48,820 **Evaluating.**\n",
      "2020-09-29 21:19:22,837 NMI: 27.503\n",
      "2020-09-29 21:19:33,661 R@1 : 31.103\n",
      "2020-09-29 21:19:33,904 R@2 : 41.123\n",
      "2020-09-29 21:19:34,146 R@4 : 52.516\n",
      "2020-09-29 21:19:34,389 R@8 : 63.361\n",
      "2020-09-29 21:20:07,260 Epoch: 16, loss: 2.766, time (seconds): 32.87.\n",
      "2020-09-29 21:20:07,261 **Evaluating.**\n",
      "2020-09-29 21:20:41,821 NMI: 27.064\n",
      "2020-09-29 21:20:53,134 R@1 : 31.025\n",
      "2020-09-29 21:20:53,381 R@2 : 41.244\n",
      "2020-09-29 21:20:53,625 R@4 : 52.107\n",
      "2020-09-29 21:20:53,870 R@8 : 62.814\n",
      "2020-09-29 21:21:27,782 Epoch: 17, loss: 2.764, time (seconds): 33.91.\n",
      "2020-09-29 21:21:27,783 **Evaluating.**\n",
      "2020-09-29 21:22:02,629 NMI: 26.933\n",
      "2020-09-29 21:22:13,991 R@1 : 30.816\n",
      "2020-09-29 21:22:14,235 R@2 : 40.680\n",
      "2020-09-29 21:22:14,481 R@4 : 51.847\n",
      "2020-09-29 21:22:14,726 R@8 : 62.918\n",
      "2020-09-29 21:22:48,596 Epoch: 18, loss: 2.761, time (seconds): 33.87.\n",
      "2020-09-29 21:22:48,597 **Evaluating.**\n",
      "2020-09-29 21:23:22,995 NMI: 27.442\n",
      "2020-09-29 21:23:34,319 R@1 : 31.007\n",
      "2020-09-29 21:23:34,569 R@2 : 41.331\n",
      "2020-09-29 21:23:34,815 R@4 : 52.133\n",
      "2020-09-29 21:23:35,075 R@8 : 62.275\n",
      "2020-09-29 21:24:08,827 Epoch: 19, loss: 2.727, time (seconds): 33.75.\n",
      "2020-09-29 21:24:08,827 **Evaluating.**\n",
      "2020-09-29 21:24:42,793 NMI: 27.359\n",
      "2020-09-29 21:24:54,025 R@1 : 31.016\n",
      "2020-09-29 21:24:54,273 R@2 : 41.227\n",
      "2020-09-29 21:24:54,517 R@4 : 51.994\n",
      "2020-09-29 21:24:54,765 R@8 : 62.788\n",
      "2020-09-29 21:24:54,767 Total training time (minutes): 28.03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-29 21:24:55,503 Training parameters: {'__module__': '__main__', 'dataset': 'food_test', 'config': 'config1.json', 'sz_embedding': 64, 'sz_batch': 128, 'nb_epochs': 20, 'gpu_id': 0, 'nb_workers': 4, 'with_nmi': True, 'scaling_x': 1.0, 'scaling_p': 1.0, 'lr_proxynca': 1, 'log_filename': 'food_test-20200929-205650', 'results_filename': 'food_test-results.csv', 'torch_version': '1.1.0', 'edition': 0, 'seed': 2, 'train_classes': range(0, 50), 'eval_classes': range(50, 101), 'p_c': 1, '__dict__': <attribute '__dict__' of 'args' objects>, '__weakref__': <attribute '__weakref__' of 'args' objects>, '__doc__': None}\n",
      "2020-09-29 21:24:55,504 Training for 20 epochs\n",
      "2020-09-29 21:24:55,505 **Evaluating initial model.**\n",
      "2020-09-29 21:25:29,972 NMI: 26.153\n",
      "2020-09-29 21:25:41,913 R@1 : 32.893\n",
      "2020-09-29 21:25:42,160 R@2 : 42.270\n",
      "2020-09-29 21:25:42,407 R@4 : 52.881\n",
      "2020-09-29 21:25:42,653 R@8 : 63.944\n",
      "2020-09-29 21:26:16,226 Epoch: 0, loss: 3.343, time (seconds): 33.57.\n",
      "2020-09-29 21:26:16,227 **Evaluating.**\n",
      "2020-09-29 21:26:50,237 NMI: 30.428\n",
      "2020-09-29 21:27:01,662 R@1 : 37.247\n",
      "2020-09-29 21:27:01,916 R@2 : 46.893\n",
      "2020-09-29 21:27:02,163 R@4 : 57.452\n",
      "2020-09-29 21:27:02,410 R@8 : 67.237\n",
      "2020-09-29 21:27:36,263 Epoch: 1, loss: 3.140, time (seconds): 33.85.\n",
      "2020-09-29 21:27:36,264 **Evaluating.**\n",
      "2020-09-29 21:28:10,581 NMI: 30.614\n",
      "2020-09-29 21:28:21,901 R@1 : 37.360\n",
      "2020-09-29 21:28:22,146 R@2 : 47.423\n",
      "2020-09-29 21:28:22,389 R@4 : 57.487\n",
      "2020-09-29 21:28:22,634 R@8 : 67.524\n",
      "2020-09-29 21:28:56,458 Epoch: 2, loss: 3.059, time (seconds): 33.82.\n",
      "2020-09-29 21:28:56,459 **Evaluating.**\n",
      "2020-09-29 21:29:31,144 NMI: 30.878\n",
      "2020-09-29 21:29:42,350 R@1 : 37.560\n",
      "2020-09-29 21:29:42,597 R@2 : 47.667\n",
      "2020-09-29 21:29:42,841 R@4 : 58.112\n",
      "2020-09-29 21:29:43,087 R@8 : 67.654\n",
      "2020-09-29 21:30:17,031 Epoch: 3, loss: 3.014, time (seconds): 33.94.\n",
      "2020-09-29 21:30:17,032 **Evaluating.**\n",
      "2020-09-29 21:30:51,304 NMI: 30.469\n",
      "2020-09-29 21:31:02,566 R@1 : 37.151\n",
      "2020-09-29 21:31:02,812 R@2 : 47.293\n",
      "2020-09-29 21:31:03,059 R@4 : 57.687\n",
      "2020-09-29 21:31:03,305 R@8 : 67.246\n",
      "2020-09-29 21:31:37,397 Epoch: 4, loss: 2.956, time (seconds): 34.09.\n",
      "2020-09-29 21:31:37,397 **Evaluating.**\n",
      "2020-09-29 21:32:13,161 NMI: 30.612\n",
      "2020-09-29 21:32:24,178 R@1 : 36.526\n",
      "2020-09-29 21:32:24,423 R@2 : 46.719\n",
      "2020-09-29 21:32:24,669 R@4 : 57.017\n",
      "2020-09-29 21:32:24,913 R@8 : 66.994\n",
      "2020-09-29 21:32:58,480 Epoch: 5, loss: 2.943, time (seconds): 33.56.\n",
      "2020-09-29 21:32:58,481 **Evaluating.**\n",
      "2020-09-29 21:33:33,574 NMI: 30.381\n",
      "2020-09-29 21:33:44,889 R@1 : 36.135\n",
      "2020-09-29 21:33:45,134 R@2 : 46.537\n",
      "2020-09-29 21:33:45,390 R@4 : 56.574\n",
      "2020-09-29 21:33:45,644 R@8 : 66.360\n",
      "2020-09-29 21:34:19,451 Epoch: 6, loss: 2.904, time (seconds): 33.81.\n",
      "2020-09-29 21:34:19,452 **Evaluating.**\n",
      "2020-09-29 21:34:54,025 NMI: 30.335\n",
      "2020-09-29 21:35:05,284 R@1 : 35.865\n",
      "2020-09-29 21:35:05,528 R@2 : 46.415\n",
      "2020-09-29 21:35:05,778 R@4 : 56.487\n",
      "2020-09-29 21:35:06,022 R@8 : 66.664\n",
      "2020-09-29 21:35:39,967 Epoch: 7, loss: 2.897, time (seconds): 33.94.\n",
      "2020-09-29 21:35:39,967 **Evaluating.**\n",
      "2020-09-29 21:36:15,679 NMI: 29.440\n",
      "2020-09-29 21:36:26,891 R@1 : 35.344\n",
      "2020-09-29 21:36:27,144 R@2 : 45.842\n",
      "2020-09-29 21:36:27,392 R@4 : 56.235\n",
      "2020-09-29 21:36:27,642 R@8 : 66.221\n",
      "2020-09-29 21:37:02,639 Epoch: 8, loss: 2.859, time (seconds): 34.99.\n",
      "2020-09-29 21:37:02,640 **Evaluating.**\n",
      "2020-09-29 21:37:40,082 NMI: 29.211\n",
      "2020-09-29 21:37:51,463 R@1 : 34.605\n",
      "2020-09-29 21:37:51,710 R@2 : 44.573\n",
      "2020-09-29 21:37:51,954 R@4 : 55.114\n",
      "2020-09-29 21:37:52,199 R@8 : 65.795\n",
      "2020-09-29 21:38:26,697 Epoch: 9, loss: 2.858, time (seconds): 34.50.\n",
      "2020-09-29 21:38:26,698 **Evaluating.**\n",
      "2020-09-29 21:39:03,460 NMI: 29.241\n",
      "2020-09-29 21:39:14,981 R@1 : 34.483\n",
      "2020-09-29 21:39:15,240 R@2 : 44.764\n",
      "2020-09-29 21:39:15,491 R@4 : 55.045\n",
      "2020-09-29 21:39:15,757 R@8 : 65.647\n",
      "2020-09-29 21:39:51,422 Epoch: 10, loss: 2.839, time (seconds): 35.66.\n",
      "2020-09-29 21:39:51,423 **Evaluating.**\n",
      "2020-09-29 21:40:28,823 NMI: 28.701\n",
      "2020-09-29 21:40:40,172 R@1 : 33.719\n",
      "2020-09-29 21:40:40,422 R@2 : 43.912\n",
      "2020-09-29 21:40:40,673 R@4 : 55.236\n",
      "2020-09-29 21:40:40,919 R@8 : 65.864\n"
     ]
    }
   ],
   "source": [
    "# lists of each parameter to search\n",
    "seeds = [0,1,2,3,4,5,6,7,-1]\n",
    "lrs = [1]\n",
    "scaling_xs = [1.0]\n",
    "scaling_ps = [1.0]\n",
    "sz_embs = [64]\n",
    "sz_batches = [128]\n",
    "eds = [0]\n",
    "train_rnges = [range(0,50)]\n",
    "eval_rnges = [range(50,101)]\n",
    "pcs = [1]\n",
    "\n",
    "results = {}\n",
    "if os.path.exists(args.results_filename):\n",
    "    results_df = pd.read_csv(args.results_filename)\n",
    "    index = 0\n",
    "else:\n",
    "    results_df = pd.DataFrame(columns = ['index','epoch', 'r@1', 'r@2', 'r@4', 'r@8', 'NMI',\n",
    "                                         'lr','scl_x','scl_p','sz_emb','seed', 'edition',\n",
    "                                         'batch', 'torch version', 'train_classes', 'eval_classes',\n",
    "                                        'p_c'])\n",
    "    index = 0\n",
    "for lr in lrs:\n",
    "    args.lr_proxynca = lr\n",
    "    for scl_x in scaling_xs:\n",
    "        args.scaling_x = scl_x\n",
    "        for scl_p in scaling_ps:\n",
    "            args.scaling_p = scl_p\n",
    "            for sz_emb in sz_embs:\n",
    "                args.sz_embedding = sz_emb\n",
    "                for seed in seeds:\n",
    "                    args.seed = seed\n",
    "                    for ed in eds:\n",
    "                        args.edition = ed\n",
    "                        for sz_batch in sz_batches:\n",
    "                            args.sz_batch = sz_batch\n",
    "                            for train_rng in train_rnges:\n",
    "                                args.train_classes = train_rng\n",
    "                                tr_rng_str = str([train_rng[0], train_rng[-1]+1])\n",
    "                                for eval_rng in eval_rnges:\n",
    "                                    args.eval_classes = eval_rng\n",
    "                                    ev_rng_str = str([eval_rng[0], eval_rng[-1]+1])\n",
    "                                    for pc in pcs:\n",
    "                                        args.p_c = pc\n",
    "                                        if (results_df[(results_df.lr == lr) & (results_df.scl_x == scl_x)\n",
    "                                                           & (results_df.scl_p == scl_p)\n",
    "                                                           & (results_df.sz_emb == sz_emb)\n",
    "                                                           & (results_df.seed == seed)\n",
    "                                                           & (results_df.edition == ed)\n",
    "                                                           & (results_df['torch version'] == args.torch_version)\n",
    "                                                           & (results_df['batch'] == sz_batch)\n",
    "                                                           & (results_df['train_classes'] == tr_rng_str)\n",
    "                                                           & (results_df['eval_classes'] == ev_rng_str)\n",
    "                                                           & (results_df['p_c'] == pc)]\n",
    "                                            .shape[0] == 0):\n",
    "                                            if results_df['index'].shape[0] > 0:\n",
    "                                                index = results_df['index'].max() + 1\n",
    "                                            print(index)\n",
    "                                            res_df = train_and_test()\n",
    "                                            res_df['lr'] = lr\n",
    "                                            res_df['scl_x'] = scl_x\n",
    "                                            res_df['scl_p'] = scl_p\n",
    "                                            res_df['index'] = index\n",
    "                                            res_df['sz_emb'] = sz_emb\n",
    "                                            res_df['seed'] = seed\n",
    "                                            res_df['edition'] = ed\n",
    "                                            res_df['batch'] = sz_batch\n",
    "                                            res_df['torch version'] = args.torch_version\n",
    "                                            res_df.loc[:,'train_classes'] = tr_rng_str\n",
    "                                            res_df.loc[:, 'eval_classes'] = ev_rng_str\n",
    "                                            res_df['p_c'] = pc\n",
    "\n",
    "                                            results_df = pd.concat([results_df, res_df])\n",
    "                                            results_df.to_csv(args.results_filename, index = False)\n",
    "                                            index+=1\n",
    "                                        else:\n",
    "                                            print(f'skipped version:{index}. It was already done.')\n",
    "                                            index+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "511.946px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
