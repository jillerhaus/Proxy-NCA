{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import imp\n",
    "import dataset\n",
    "import utils\n",
    "import proxynca\n",
    "import net\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "from utils import JSONEncoder, json_dumps\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Args Class\n",
    "\n",
    "Class containing the parameters for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args():\n",
    "    dataset = 'food_test'\n",
    "    config = 'config1.json'\n",
    "    sz_embedding = 64 #size of the embedding that is appendet to inceptionv2\n",
    "    sz_batch = 32 #number of samples per batch\n",
    "    nb_epochs = 20\n",
    "    gpu_id = 0\n",
    "    nb_workers = 4\n",
    "    with_nmi = True  #turn calculations for nmi on or off turn off for sop\n",
    "    scaling_x = 3.0 #scaling factor for the normalized embeddings\n",
    "    scaling_p = 3.0 #scaling factor for the normalized proxies\n",
    "    lr_proxynca = 1.0 #learning rate for proxynca\n",
    "    log_filename = (f'''{dataset}-{dt.now().strftime(\"%Y%m%d-%H%M%S\")}''')\n",
    "    results_filename = f'{dataset}-results.csv'\n",
    "    torch_version = str(torch.__version__)\n",
    "    edition = 0\n",
    "    seed = 0\n",
    "    train_classes = None\n",
    "    eval_classes = None\n",
    "    p_c = 1 #Number of proxies per class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(args = args):\n",
    "    seed = args.seed\n",
    "    if seed != -1:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    else:\n",
    "        print('not seeded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(args.gpu_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_config(args = args):\n",
    "    config = utils.load_config(args.config)\n",
    "    config['criterion']['args']['scaling_x'] = args.scaling_x\n",
    "    config['criterion']['args']['scaling_p'] = args.scaling_p\n",
    "    config['opt']['args']['proxynca']['lr'] = args.lr_proxynca\n",
    "    if args.train_classes:\n",
    "        config['dataset'][args.dataset]['classes']['train'] = args.train_classes\n",
    "    if args.eval_classes:\n",
    "        config['dataset'][args.dataset]['classes']['eval'] = args.eval_classes\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_tr(config = setup_config(), args = args):\n",
    "    dl_tr = torch.utils.data.DataLoader(\n",
    "        dataset.load(name = args.dataset,\n",
    "                     root = config['dataset'][args.dataset]['root'],\n",
    "                     classes = config['dataset'][args.dataset]['classes']['train'],\n",
    "                     transform = dataset.utils.make_transform(**config['transform_parameters'])\n",
    "                    ),\n",
    "        batch_size = args.sz_batch,\n",
    "        shuffle = True,\n",
    "        num_workers = args.nb_workers,\n",
    "        drop_last = True,\n",
    "        pin_memory = True\n",
    "    )\n",
    "    return dl_tr\n",
    "\n",
    "def load_ev(config = setup_config(), args = args):\n",
    "    dl_ev = torch.utils.data.DataLoader(\n",
    "        dataset.load(\n",
    "            name = args.dataset,\n",
    "            root = config['dataset'][args.dataset]['root'],\n",
    "            classes = config['dataset'][args.dataset]['classes']['eval'],\n",
    "            transform = dataset.utils.make_transform(\n",
    "                **config['transform_parameters'],\n",
    "                is_train = False)\n",
    "        ),\n",
    "        batch_size = args.sz_batch,\n",
    "        shuffle = False,\n",
    "        num_workers = args.nb_workers,\n",
    "        pin_memory = True\n",
    "    )\n",
    "    return dl_ev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model(args = args):\n",
    "    model = net.bn_inception(pretrained = True)\n",
    "    net.embed(model, sz_embedding = args.sz_embedding)\n",
    "    model = model.cuda()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterion\n",
    "\n",
    "This function initializes the training class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_criterion(config = setup_config(), args = args, dl_tr = load_tr()):\n",
    "    criterion = proxynca.ProxyNCA(\n",
    "        nb_classes = dl_tr.dataset.nb_classes(),\n",
    "        sz_embedding = args.sz_embedding,\n",
    "        p_c = args.p_c,\n",
    "        **config['criterion']['args']).cuda()\n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_opt(config = setup_config(), model = setup_model(), criterion = setup_criterion()):\n",
    "    opt = config['opt']['type'](\n",
    "        [\n",
    "            { # inception parameters, excluding embedding layer\n",
    "                **{'params': list(\n",
    "                    set(\n",
    "                        model.parameters()\n",
    "                    ).difference(\n",
    "                        set(model.embedding_layer.parameters())\n",
    "                    )\n",
    "                )},\n",
    "                **config['opt']['args']['backbone']\n",
    "            },\n",
    "            { # embedding parameters\n",
    "                **{'params': model.embedding_layer.parameters()},\n",
    "                **config['opt']['args']['embedding']\n",
    "            },\n",
    "            { # proxy nca parameters\n",
    "                **{'params': criterion.parameters()},\n",
    "                **config['opt']['args']['proxynca']\n",
    "            }\n",
    "        ],\n",
    "        **config['opt']['args']['base']\n",
    "    )\n",
    "    return opt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_scheduler(config = setup_config(), opt = setup_opt()):\n",
    "    scheduler = config['lr_scheduler']['type'](\n",
    "        opt, **config['lr_scheduler']['args'])\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging(args = args):\n",
    "    imp.reload(logging)\n",
    "    logging.basicConfig(\n",
    "        format = \"%(asctime)s %(message)s\",\n",
    "        level = logging.INFO,\n",
    "        handlers = [\n",
    "            logging.FileHandler(\"{0}/{1}.log\".format('log', args.log_filename)),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    logging.info(\"Training parameters: {}\".format(vars(args)))\n",
    "    logging.info(\"Training for {} epochs\".format(args.nb_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(args = args):\n",
    "    #set up new parameters\n",
    "    seed_everything(args)\n",
    "    config = setup_config(args)\n",
    "    dl_tr = load_tr(config, args)\n",
    "    dl_ev = load_ev(config, args)\n",
    "    model = setup_model(args = args)\n",
    "    criterion = setup_criterion(config = config, args = args, dl_tr = load_tr())\n",
    "    opt = setup_opt(config = config, model = model, criterion = criterion)\n",
    "    scheduler = setup_scheduler(config = config, opt = opt)\n",
    "    setup_logging(args = args)\n",
    "    \n",
    "    if args.with_nmi == True:\n",
    "        df = pd.DataFrame(columns = ['epoch', 'r@1', 'r@2', 'r@4', 'r@8', 'NMI'])\n",
    "    else:\n",
    "        df = pd.DataFrame(columns = ['epoch', 'r@1', 'r@2', 'r@4','r@8'])\n",
    "    \n",
    "    losses = []\n",
    "    t1 = time.time()\n",
    "    logging.info(\"**Evaluating initial model.**\")\n",
    "    with torch.no_grad():\n",
    "        utils.evaluate(model, dl_ev, with_nmi = args.with_nmi)\n",
    "\n",
    "    for e in range(0, args.nb_epochs):\n",
    "        if e!=0:\n",
    "            scheduler.step()\n",
    "        time_per_epoch_1 = time.time()\n",
    "        losses_per_epoch = []\n",
    "        for x,y, _ in dl_tr:\n",
    "            opt.zero_grad()\n",
    "            m = model(x.cuda())\n",
    "            loss = criterion(m, y.cuda())\n",
    "            loss.backward()\n",
    "\n",
    "#             torch.nn.utils.clip_grad_value_(model.parameters(), 10)\n",
    "            \n",
    "            losses_per_epoch.append(loss.data.cpu().numpy())\n",
    "            opt.step()\n",
    "\n",
    "        time_per_epoch_2 = time.time()\n",
    "        losses.append(np.mean(losses_per_epoch[-20:]))\n",
    "        logging.info(\n",
    "            \"Epoch: {}, loss: {:.3f}, time (seconds): {:.2f}.\".format(\n",
    "                e,\n",
    "                losses[-1],\n",
    "                time_per_epoch_2 - time_per_epoch_1))\n",
    "        with torch.no_grad():\n",
    "            logging.info(\"**Evaluating.**\")\n",
    "            recall = utils.evaluate(model, dl_ev, with_nmi = args.with_nmi) #variable name not accurate\n",
    "            # append results of current epoch to df\n",
    "            if args.with_nmi == True:\n",
    "                lst = recall[0].copy()\n",
    "                lst.append(recall[1])\n",
    "                lst.insert(0,e)\n",
    "                df_epoch = pd.DataFrame([lst], columns = ['epoch', 'r@1', 'r@2', 'r@4','r@8', 'NMI'])\n",
    "            else:\n",
    "                lst = recall.copy()\n",
    "                lst.insert(0,e)\n",
    "                df_epoch = pd.DataFrame([lst], columns = ['epoch', 'r@1', 'r@2', 'r@4', 'r@8'])\n",
    "            df = pd.concat([df,df_epoch])\n",
    "            model.losses = losses\n",
    "            model.current_epoch = e\n",
    "\n",
    "    t2 = time.time()\n",
    "    logging.info(\"Total training time (minutes): {:.2f}.\".format((t2 - t1) / 60))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lists of each parameter to search\n",
    "seeds = [0,1,2,3,4,5,6,7,-1]\n",
    "lrs = [1]\n",
    "scaling_xs = [1.0]\n",
    "scaling_ps = [1.0]\n",
    "sz_embs = [64]\n",
    "sz_batches = [128]\n",
    "eds = [0]\n",
    "train_rnges = [range(0,50)]\n",
    "eval_rnges = [range(50,101)]\n",
    "pcs = [1]\n",
    "\n",
    "results = {}\n",
    "if os.path.exists(args.results_filename):\n",
    "    results_df = pd.read_csv(args.results_filename)\n",
    "    index = 0\n",
    "else:\n",
    "    results_df = pd.DataFrame(columns = ['index','epoch', 'r@1', 'r@2', 'r@4', 'r@8', 'NMI',\n",
    "                                         'lr','scl_x','scl_p','sz_emb','seed', 'edition',\n",
    "                                         'batch', 'torch version', 'train_classes', 'eval_classes',\n",
    "                                        'p_c'])\n",
    "    index = 0\n",
    "for lr in lrs:\n",
    "    args.lr_proxynca = lr\n",
    "    for scl_x in scaling_xs:\n",
    "        args.scaling_x = scl_x\n",
    "        for scl_p in scaling_ps:\n",
    "            args.scaling_p = scl_p\n",
    "            for sz_emb in sz_embs:\n",
    "                args.sz_embedding = sz_emb\n",
    "                for seed in seeds:\n",
    "                    args.seed = seed\n",
    "                    for ed in eds:\n",
    "                        args.edition = ed\n",
    "                        for sz_batch in sz_batches:\n",
    "                            args.sz_batch = sz_batch\n",
    "                            for train_rng in train_rnges:\n",
    "                                args.train_classes = train_rng\n",
    "                                tr_rng_str = str([train_rng[0], train_rng[-1]+1])\n",
    "                                for eval_rng in eval_rnges:\n",
    "                                    args.eval_classes = eval_rng\n",
    "                                    ev_rng_str = str([eval_rng[0], eval_rng[-1]+1])\n",
    "                                    for pc in pcs:\n",
    "                                        args.p_c = pc\n",
    "                                        if (results_df[(results_df.lr == lr) & (results_df.scl_x == scl_x)\n",
    "                                                           & (results_df.scl_p == scl_p)\n",
    "                                                           & (results_df.sz_emb == sz_emb)\n",
    "                                                           & (results_df.seed == seed)\n",
    "                                                           & (results_df.edition == ed)\n",
    "                                                           & (results_df['torch version'] == args.torch_version)\n",
    "                                                           & (results_df['batch'] == sz_batch)\n",
    "                                                           & (results_df['train_classes'] == tr_rng_str)\n",
    "                                                           & (results_df['eval_classes'] == ev_rng_str)\n",
    "                                                           & (results_df['p_c'] == pc)]\n",
    "                                            .shape[0] == 0):\n",
    "                                            if results_df['index'].shape[0] > 0:\n",
    "                                                index = results_df['index'].max() + 1\n",
    "                                            print(index)\n",
    "                                            res_df = train_and_test()\n",
    "                                            res_df['lr'] = lr\n",
    "                                            res_df['scl_x'] = scl_x\n",
    "                                            res_df['scl_p'] = scl_p\n",
    "                                            res_df['index'] = index\n",
    "                                            res_df['sz_emb'] = sz_emb\n",
    "                                            res_df['seed'] = seed\n",
    "                                            res_df['edition'] = ed\n",
    "                                            res_df['batch'] = sz_batch\n",
    "                                            res_df['torch version'] = args.torch_version\n",
    "                                            res_df.loc[:,'train_classes'] = tr_rng_str\n",
    "                                            res_df.loc[:, 'eval_classes'] = ev_rng_str\n",
    "                                            res_df['p_c'] = pc\n",
    "\n",
    "                                            results_df = pd.concat([results_df, res_df])\n",
    "                                            results_df.to_csv(args.results_filename, index = False)\n",
    "                                            index+=1\n",
    "                                        else:\n",
    "                                            print(f'skipped version:{index}. It was already done.')\n",
    "                                            index+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "511.946px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
