{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"criterion\": {\n",
      "        \"args\": {\n",
      "            \"scaling_p\": 3.0,\n",
      "            \"scaling_x\": 3.0,\n",
      "            \"smoothing_const\": 0.1\n",
      "        },\n",
      "        \"type\": \"<class 'proxynca.ProxyNCA'>\"\n",
      "    },\n",
      "    \"dataset\": {\n",
      "        \"cars\": {\n",
      "            \"classes\": {\n",
      "                \"eval\": \"range(98, 196)\",\n",
      "                \"train\": \"range(0, 98)\"\n",
      "            },\n",
      "            \"root\": \"C:/Users/apist/Pictures/Moon_Vision_Datasets/cars196\"\n",
      "        },\n",
      "        \"cub\": {\n",
      "            \"classes\": {\n",
      "                \"eval\": \"range(100, 200)\",\n",
      "                \"train\": \"range(0, 100)\"\n",
      "            },\n",
      "            \"root\": \"C:/Users/apist/Pictures/Moon_Vision_Datasets/cub_200_2011/cub_200_2011\"\n",
      "        },\n",
      "        \"food\": {\n",
      "            \"classes\": {\n",
      "                \"eval\": \"range(50, 101)\",\n",
      "                \"train\": \"range(0, 50)\"\n",
      "            },\n",
      "            \"root\": \"C:/Users/apist/Pictures/Moon_Vision_Datasets/UPMC_Food101/images\"\n",
      "        },\n",
      "        \"sop\": {\n",
      "            \"classes\": {\n",
      "                \"eval\": \"range(11318, 22634)\",\n",
      "                \"train\": \"range(0, 11318)\"\n",
      "            },\n",
      "            \"root\": \"/export/home/vtschern/data/sop\"\n",
      "        }\n",
      "    },\n",
      "    \"gpu_id\": 0,\n",
      "    \"lr_scheduler\": {\n",
      "        \"args\": {\n",
      "            \"gamma\": 0.94\n",
      "        },\n",
      "        \"type\": \"<class 'torch.optim.lr_scheduler.ExponentialLR'>\"\n",
      "    },\n",
      "    \"name\": \"example\",\n",
      "    \"opt\": {\n",
      "        \"args\": {\n",
      "            \"backbone\": {\n",
      "                \"weight_decay\": 0.0\n",
      "            },\n",
      "            \"base\": {\n",
      "                \"eps\": 1.0,\n",
      "                \"lr\": 0.045\n",
      "            },\n",
      "            \"embedding\": {\n",
      "                \"weight_decay\": 0.0\n",
      "            },\n",
      "            \"proxynca\": {\n",
      "                \"lr\": 1.0,\n",
      "                \"weight_decay\": 0.0\n",
      "            }\n",
      "        },\n",
      "        \"type\": \"<class 'torch.optim.adam.Adam'>\"\n",
      "    },\n",
      "    \"transform_parameters\": {\n",
      "        \"intensity_scale\": [\n",
      "            [\n",
      "                0,\n",
      "                1\n",
      "            ],\n",
      "            [\n",
      "                0,\n",
      "                255\n",
      "            ]\n",
      "        ],\n",
      "        \"mean\": [\n",
      "            104,\n",
      "            117,\n",
      "            128\n",
      "        ],\n",
      "        \"rgb_to_bgr\": true,\n",
      "        \"std\": [\n",
      "            1,\n",
      "            1,\n",
      "            1\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-05 12:17:18,681 Training parameters: {'__module__': '__main__', 'dataset': 'cub', 'config': 'config1.json', 'sz_embedding': 64, 'sz_batch': 32, 'nb_epochs': 20, 'log_filename': 'cub-20200905-121716', 'gpu_id': 0, 'nb_workers': 4, 'with_nmi': True, 'scaling_x': 3.0, 'scaling_p': 3.0, 'lr_proxynca': 1.0, '__dict__': <attribute '__dict__' of 'args' objects>, '__weakref__': <attribute '__weakref__' of 'args' objects>, '__doc__': None}\n",
      "2020-09-05 12:17:18,681 Training for 20 epochs.\n",
      "2020-09-05 12:17:18,682 **Evaluating initial model...**\n",
      "2020-09-05 12:17:32,514 NMI: 46.347\n",
      "2020-09-05 12:17:33,186 R@1 : 32.394\n",
      "2020-09-05 12:17:33,259 R@2 : 44.615\n",
      "2020-09-05 12:17:33,332 R@4 : 57.444\n",
      "2020-09-05 12:17:33,406 R@8 : 70.611\n",
      "C:\\Users\\apist\\.conda\\envs\\gwded\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "C:\\Users\\apist\\.conda\\envs\\gwded\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "2020-09-05 12:17:57,905 Epoch: 0, loss: 4.111, time (seconds): 24.50.\n",
      "2020-09-05 12:17:57,906 **Evaluating...**\n",
      "2020-09-05 12:18:11,056 NMI: 39.567\n",
      "2020-09-05 12:18:11,769 R@1 : 18.518\n",
      "2020-09-05 12:18:11,847 R@2 : 27.431\n",
      "2020-09-05 12:18:11,926 R@4 : 39.315\n",
      "2020-09-05 12:18:12,005 R@8 : 53.309\n",
      "C:\\Users\\apist\\.conda\\envs\\gwded\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "2020-09-05 12:18:38,111 Epoch: 1, loss: 3.161, time (seconds): 26.10.\n",
      "2020-09-05 12:18:38,112 **Evaluating...**\n",
      "2020-09-05 12:18:50,632 NMI: 46.366\n",
      "2020-09-05 12:18:51,325 R@1 : 26.604\n",
      "2020-09-05 12:18:51,398 R@2 : 37.559\n",
      "2020-09-05 12:18:51,471 R@4 : 50.827\n",
      "2020-09-05 12:18:51,544 R@8 : 63.707\n",
      "C:\\Users\\apist\\.conda\\envs\\gwded\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "2020-09-05 12:19:15,570 Epoch: 2, loss: 2.789, time (seconds): 24.02.\n",
      "2020-09-05 12:19:15,571 **Evaluating...**\n",
      "2020-09-05 12:19:28,432 NMI: 48.716\n",
      "2020-09-05 12:19:29,118 R@1 : 29.997\n",
      "2020-09-05 12:19:29,195 R@2 : 41.948\n",
      "2020-09-05 12:19:29,274 R@4 : 54.355\n",
      "2020-09-05 12:19:29,348 R@8 : 67.505\n",
      "C:\\Users\\apist\\.conda\\envs\\gwded\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "2020-09-05 12:19:55,156 Epoch: 3, loss: 2.525, time (seconds): 25.81.\n",
      "2020-09-05 12:19:55,157 **Evaluating...**\n",
      "2020-09-05 12:20:08,118 NMI: 47.904\n",
      "2020-09-05 12:20:08,783 R@1 : 30.841\n",
      "2020-09-05 12:20:08,857 R@2 : 42.623\n",
      "2020-09-05 12:20:08,930 R@4 : 54.777\n",
      "2020-09-05 12:20:09,003 R@8 : 67.589\n",
      "C:\\Users\\apist\\.conda\\envs\\gwded\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "2020-09-05 12:20:33,715 Epoch: 4, loss: 2.282, time (seconds): 24.71.\n",
      "2020-09-05 12:20:33,716 **Evaluating...**\n",
      "2020-09-05 12:20:46,666 NMI: 50.396\n",
      "2020-09-05 12:20:47,358 R@1 : 33.525\n",
      "2020-09-05 12:20:47,435 R@2 : 45.257\n",
      "2020-09-05 12:20:47,512 R@4 : 59.200\n",
      "2020-09-05 12:20:47,589 R@8 : 70.324\n",
      "C:\\Users\\apist\\.conda\\envs\\gwded\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "2020-09-05 12:21:13,304 Epoch: 5, loss: 2.274, time (seconds): 25.71.\n",
      "2020-09-05 12:21:13,305 **Evaluating...**\n",
      "2020-09-05 12:21:26,469 NMI: 50.560\n",
      "2020-09-05 12:21:27,187 R@1 : 33.592\n",
      "2020-09-05 12:21:27,265 R@2 : 46.337\n",
      "2020-09-05 12:21:27,345 R@4 : 58.238\n",
      "2020-09-05 12:21:27,421 R@8 : 70.358\n",
      "C:\\Users\\apist\\.conda\\envs\\gwded\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "2020-09-05 12:21:53,929 Epoch: 6, loss: 2.013, time (seconds): 26.51.\n",
      "2020-09-05 12:21:53,930 **Evaluating...**\n",
      "2020-09-05 12:22:06,567 NMI: 49.333\n",
      "2020-09-05 12:22:07,267 R@1 : 32.883\n",
      "2020-09-05 12:22:07,343 R@2 : 44.480\n",
      "2020-09-05 12:22:07,419 R@4 : 57.478\n",
      "2020-09-05 12:22:07,495 R@8 : 70.814\n",
      "C:\\Users\\apist\\.conda\\envs\\gwded\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-07e65381b3f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mlosses_per_epoch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[0mtime_per_epoch_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gwded\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gwded\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gwded\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import logging\n",
    "import importlib as imp\n",
    "import dataset\n",
    "import utils\n",
    "import proxynca\n",
    "import net\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('agg', force=True)\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import argparse\n",
    "import json\n",
    "import random\n",
    "from utils import JSONEncoder, json_dumps\n",
    "from datetime import datetime as dt\n",
    "\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed) # set random seed for all gpus\n",
    "\n",
    "\n",
    "class args():\n",
    "    dataset = 'cub'\n",
    "    config = 'config1.json'\n",
    "    sz_embedding = 64 #size of the embedding that is appendet to inceptionv2\n",
    "    sz_batch = 32 #number of samples per batch\n",
    "    nb_epochs = 20\n",
    "    log_filename = f'{dataset}-{dt.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "    gpu_id = 0\n",
    "    nb_workers = 4\n",
    "    with_nmi = True  #turn calculations for nmi on or off turn off for sop\n",
    "    scaling_x = 3.0 #scaling factor for the normalized embeddings\n",
    "    scaling_p = 3.0 #scaling factor for the normalized proxies\n",
    "    lr_proxynca = 1.0 #learning rate for proxynca\n",
    "\n",
    "torch.cuda.set_device(args.gpu_id)\n",
    "\n",
    "config = utils.load_config(args.config)\n",
    "\n",
    "# adjust config parameters according to args\n",
    "config['criterion']['args']['scaling_x'] = args.scaling_x\n",
    "config['criterion']['args']['scaling_p'] = args.scaling_p\n",
    "config['opt']['args']['proxynca']['lr'] = args.lr_proxynca\n",
    "\n",
    "print(json_dumps(obj = config, indent=4, cls = JSONEncoder, sort_keys = True))\n",
    "with open('log/' + args.log_filename + '.json', 'w') as x:\n",
    "    json.dump(\n",
    "        obj = config, fp = x, indent=4, cls = JSONEncoder, sort_keys = True\n",
    "    )\n",
    "\n",
    "dl_tr = torch.utils.data.DataLoader(\n",
    "    dataset.load(\n",
    "        name = args.dataset,\n",
    "        root = config['dataset'][args.dataset]['root'],\n",
    "        classes = config['dataset'][args.dataset]['classes']['train'],\n",
    "        transform = dataset.utils.make_transform(\n",
    "            **config['transform_parameters']\n",
    "        )\n",
    "    ),\n",
    "    batch_size = args.sz_batch,\n",
    "    shuffle = True,\n",
    "    num_workers = args.nb_workers,\n",
    "    drop_last = True,\n",
    "    pin_memory = True\n",
    ")\n",
    "\n",
    "dl_ev = torch.utils.data.DataLoader(\n",
    "    dataset.load(\n",
    "        name = args.dataset,\n",
    "        root = config['dataset'][args.dataset]['root'],\n",
    "        classes = config['dataset'][args.dataset]['classes']['eval'],\n",
    "        transform = dataset.utils.make_transform(\n",
    "            **config['transform_parameters'],\n",
    "            is_train = False\n",
    "        )\n",
    "    ),\n",
    "    batch_size = args.sz_batch,\n",
    "    shuffle = False,\n",
    "    num_workers = args.nb_workers,\n",
    "    pin_memory = True\n",
    ")\n",
    "\n",
    "model = net.bn_inception(pretrained = True)\n",
    "net.embed(model, sz_embedding=args.sz_embedding)\n",
    "model = model.cuda()\n",
    "\n",
    "criterion = proxynca.ProxyNCA(\n",
    "    nb_classes = dl_tr.dataset.nb_classes(),\n",
    "    sz_embedding = args.sz_embedding,\n",
    "    **config['criterion']['args']\n",
    ").cuda()\n",
    "\n",
    "opt = config['opt']['type'](\n",
    "    [\n",
    "        { # inception parameters, excluding embedding layer\n",
    "            **{'params': list(\n",
    "                set(\n",
    "                    model.parameters()\n",
    "                ).difference(\n",
    "                    set(model.embedding_layer.parameters())\n",
    "                )\n",
    "            )},\n",
    "            **config['opt']['args']['backbone']\n",
    "        },\n",
    "        { # embedding parameters\n",
    "            **{'params': model.embedding_layer.parameters()},\n",
    "            **config['opt']['args']['embedding']\n",
    "        },\n",
    "        { # proxy nca parameters\n",
    "            **{'params': criterion.parameters()},\n",
    "            **config['opt']['args']['proxynca']\n",
    "        }\n",
    "    ],\n",
    "    **config['opt']['args']['base']\n",
    ")\n",
    "\n",
    "scheduler = config['lr_scheduler']['type'](\n",
    "    opt, **config['lr_scheduler']['args']\n",
    ")\n",
    "\n",
    "imp.reload(logging)\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s %(message)s\",\n",
    "    level=logging.INFO,\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format('log', args.log_filename)),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logging.info(\"Training parameters: {}\".format(vars(args)))\n",
    "logging.info(\"Training for {} epochs.\".format(args.nb_epochs))\n",
    "losses = []\n",
    "\n",
    "t1 = time.time()\n",
    "logging.info(\"**Evaluating initial model...**\")\n",
    "with torch.no_grad():\n",
    "    utils.evaluate(model, dl_ev, with_nmi = args.with_nmi)\n",
    "\n",
    "for e in range(0, args.nb_epochs):\n",
    "    scheduler.step(e)\n",
    "    time_per_epoch_1 = time.time()\n",
    "    losses_per_epoch = []\n",
    "\n",
    "    for x, y, _ in dl_tr:\n",
    "        opt.zero_grad()\n",
    "        m = model(x.cuda())\n",
    "        loss = criterion(m, y.cuda())\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_value_(model.parameters(), 10)\n",
    "\n",
    "        losses_per_epoch.append(loss.data.cpu().numpy())\n",
    "        opt.step()\n",
    "\n",
    "    time_per_epoch_2 = time.time()\n",
    "    losses.append(np.mean(losses_per_epoch[-20:]))\n",
    "    logging.info(\n",
    "        \"Epoch: {}, loss: {:.3f}, time (seconds): {:.2f}.\".format(\n",
    "            e,\n",
    "            losses[-1],\n",
    "            time_per_epoch_2 - time_per_epoch_1\n",
    "        )\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        logging.info(\"**Evaluating...**\")\n",
    "        utils.evaluate(model, dl_ev, with_nmi = args.with_nmi)\n",
    "    model.losses = losses\n",
    "    model.current_epoch = e\n",
    "\n",
    "t2 = time.time()\n",
    "logging.info(\"Total training time (minutes): {:.2f}.\".format((t2 - t1) / 60))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
